# LLM-Decision-Making-Benchmarking

Question Answering (QA) systems are capable of generating answers based on training data and user prompting. It stands that the accuracy and reliability of these systems are paramount. Often taking the form of Large Language Models (LLMs), they are tasked with generating responses from a diverse array of sources. However, the presence of conflicting information within these sources presents a significant challenge, potentially undermining the credibility and effectiveness of the answers provided. This study aimed to critically assess how LLM QA retrieval models prioritize conflicting data. Through a series of linguistic characteristics, and prompt variations, we investigated the decision-making criteria these models employ when presented with conflicting information.
